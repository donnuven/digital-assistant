# digital-assistant

[![emma.png](https://i.postimg.cc/vBK8Cj7h/emma.png)](https://postimg.cc/VrjcCKV0)

## Purpose summary:
This particular project known as Extension Management Machine Assistant(E.M.M.A.) is mostly a learning experience in using various different libraries to develop a digital assistant that can do various tasks for the user, similar to Alexa, Siri, and Google Home. While this is a very early iteration, it has a wide array of functionalities from doing searches on the internet to playing music for the user. There will be future iterations of this project.

## How to run this project:
To run this project, simply type in the terminal: ``python speech.py`` and this project is currently running under ``python 3.7``

## Additional Note:
In the configuration file under ``config.py`` please add in the details of the following:

+ WOLFRAM_ID: YOUR WOLFRAM API KEY
+ username: your email
+ password: your email password
+ code: /path/to/your/code_editor
+ play_directory: /path/to/your/music_file
+ root_user: your name
+ chat_log: if you plan on using rainmeter it would be /path/to/your/chat_log/chat.txt
+ shutdown: path/to/your/sound_file/shutdown.wav

## Interface Development:
The development of the interface that I found appealing was to use a rainmeter skin interface to display the information of what the digital assistant was presenting whenever a query was answered. Essentially, I combined python with a fairly simple ``.ini`` script and had it be displayed there. Below is the current interface.

[![emma-interface.png](https://i.postimg.cc/13FWFNY3/emma-interface.png)](https://postimg.cc/jDsQ0Cbp)

## Demonstration of the digital-assistant:E.M.M.A.

Soon:tm:

